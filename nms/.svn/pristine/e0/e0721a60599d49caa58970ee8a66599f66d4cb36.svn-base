package com.kuaidu.nms.spider.down;

import java.net.URLDecoder;
import java.util.ArrayList;
import java.util.Collections;
import java.util.HashMap;
import java.util.HashSet;
import java.util.List;
import java.util.Map;
import java.util.Set;

import org.apache.ibatis.javassist.expr.NewArray;
import org.springframework.stereotype.Component;
import org.springframework.web.bind.annotation.RequestBody;

import com.alibaba.fastjson.JSONObject;
import com.kuaidu.nms.config.Config;
import com.kuaidu.nms.entity.ChapterList;
import com.kuaidu.nms.entity.ReplaceConfig;
import com.kuaidu.nms.entity.SpiderConfig;
import com.kuaidu.nms.utils.Log4jUtil;
import com.kuaidu.nms.utils.Utils;
import com.kuaidu.nms.utils.spider.SpiderStart;

import us.codecraft.webmagic.Page;
import us.codecraft.webmagic.Request;
import us.codecraft.webmagic.Site;
import us.codecraft.webmagic.Spider;
import us.codecraft.webmagic.model.HttpRequestBody;
import us.codecraft.webmagic.processor.PageProcessor;
import us.codecraft.webmagic.selector.Html;
import us.codecraft.webmagic.utils.HttpConstant;

@Component
public class WebSpiderTest implements PageProcessor {
	private Site site = Site.me().setRetryTimes(0).setTimeOut(3000).setSleepTime(2)
			.setAcceptStatCode(SpiderStart.AcceptStatCode)
			.addHeader("User-Agent",
					"Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.132 Safari/537.36")
			// .addHeader("Accept",
			// "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*;q=0.8")
			// .addHeader("Accept-Encoding", "gzip, deflate, br")
			.addHeader("Cookie",
					"UM_distinctid=1656ab95471216-0e236831762a7b-323b5b03-1fa400-1656ab954722a1; Hm_lvt_848be1a5024c8d8b8651bf2ac8a92035=1535093856; CNZZDATA1255969718=1197145613-1535088496-https%253A%252F%252Fwww.baidu.com%252F%7C1535093896; Hm_lpvt_848be1a5024c8d8b8651bf2ac8a92035=1535093915")
			.addHeader("Accept", "*").addHeader("Content-Type", "text/plain; charset=utf-8")
			.addHeader("Accept-Language", "zh-CN,zh;q=0.8").addHeader("Connection", "close")
			.addHeader("Upgrade-Insecure-Requests", "1");
	private volatile static Spider spider;

	public static Spider getSpider() {
		synchronized (WebSpiderTest.class) {
			if (spider == null) {
				spider = new Spider(new WebSpiderTest());
			}
		}
		return spider;
	}

	private static JSONObject ret = new JSONObject();;

	@Override
	public void process(Page page) {
		//System.out.println(page.getHtml());
		List<String> chapterContents1 = page.getHtml().xpath("//body").all();
		System.out.println(chapterContents1);
		SpiderConfig sConfig = new SpiderConfig();
		
		sConfig.setContent_next_page_name_reg("//div[@class='page']/a/text()");
		sConfig.setContent_next_page_reg("//div[@class='page']/a");
		sConfig.setChapter_name("//div[@class='articleTitle']/h2/text()");
		sConfig.setContent_reg("//div[@class='articleCon']");
		sConfig.setCharset("gbk");
		sConfig.setContent_next_page_name("下一");
		String statusCode = String.valueOf(page.getStatusCode());
		if (statusCode.startsWith("2") || statusCode.startsWith("3")) {
			Map<String, Object> extras = page.getRequest().getExtras();
			String cn = (String) extras.get("cn");// 获取章节名称
			if (null != cn) {
				cn = URLDecoder.decode(cn);
			} else {
				Log4jUtil.getBusinessLogger().error("cn=" + page.getUrl());
				return;
			}
			String url = page.getUrl().toString();
			String pre_url = url.substring(0, url.lastIndexOf('/') + 1);
			//System.out.println(page.toString());
			StringBuilder chapterContent = new StringBuilder(500);
			List<String> chapterContents = page.getHtml().xpath(sConfig.getContent_reg()).all();
			List<ReplaceConfig> replaces = new ArrayList<ReplaceConfig>();
			Log4jUtil.getBusinessLogger().info(cn + "===get first page");
			int words_min = 800;
			if (chapterContents.size() > 0) {
				try {
					replaces = new ArrayList<ReplaceConfig>();

					// System.out.println(replaces.toString());
				} catch (Exception e) {
					// TODO Auto-generated catch block
					e.printStackTrace();
				}
				chapterContent.append(Utils.replace(chapterContents.get(0), replaces).trim());
			}
			Log4jUtil.getBusinessLogger().info(cn + "===begin next page, words_min==" + words_min);

			if (null != sConfig.getContent_next_page_name_reg() && null != sConfig.getContent_next_page_reg()
					&& null != sConfig.getChapter_name() && !sConfig.getContent_next_page_name_reg().equals("")
					&& !sConfig.getContent_next_page_reg().equals("") && !sConfig.getChapter_name().equals("")) {
				List<String> next_page_name = page.getHtml().xpath(sConfig.getContent_next_page_name_reg()).all();
				List<String> next_page_url = page.getHtml().xpath(sConfig.getContent_next_page_reg()).links().all();
				List<String> chapter_names = page.getHtml().xpath(sConfig.getChapter_name()).all();
				System.out.println(next_page_name.toString());
				System.out.println(next_page_url.toString());
				System.out.println(chapter_names.toString());
				if (next_page_name.size() <= 0 || next_page_url.size() <= 0 || chapter_names.size() <= 0) {// 下一页规则不正确
					Log4jUtil.getSimpleErrorLogger().error(cn + "=== next page regex error!");
					chapterContent.delete(0, chapterContent.length());
				} else {
					Utils.threadSleep(200);
					String nextChapterContent = Utils.getNextPageContent(next_page_url, next_page_name, sConfig,
							replaces, cn, pre_url);
					if (nextChapterContent == null) {
						// 有有一个下一页加载失败
						// 清空每一页内容
						Log4jUtil.getSimpleErrorLogger().error(cn + "=== next page load failed!");
						chapterContent.delete(0, chapterContent.length());
					} else {
						chapterContent.append(nextChapterContent);

					}
				}
			}
			System.out.println(chapterContent.toString());
		}
	}

	private List<ReplaceConfig> getReplaceList() {
		// TODO Auto-generated method stub
		List<ReplaceConfig> replaces = new ArrayList<ReplaceConfig>();

		return null;
	}

	@Override
	public Site getSite() {
		// TODO Auto-generated method stub
		// site.setCharset("gb2312");
		return site;
	}

	public JSONObject BeginSpider(String... urls) {
		Request[] res = new Request[urls.length];
		List<Request> requests = new ArrayList<Request>();
		for (String url : urls) {
			Request request = new Request(url);
			Map<String, Object> extras = new HashMap<String, Object>();
			request.setRemoverDuplicate(false);
			request.setMethod(HttpConstant.Method.GET);
			extras.put("ct", "1536132681347");
			extras.put("t", "2");
			extras.put("book_id", "3134");
			extras.put("cn",
					"%e7%ac%ac159%e7%ab%a0+%e7%ae%a1%e7%9a%84%e5%a4%aa%e5%a4%9a");

			request.setExtras(extras);
			requests.add(request);
		}

		spider = getSpider();
		spider.addRequest(requests.toArray(res));
		if (spider.getStatus().equals(Spider.Status.Running)) {
			// spider.addUrl(urls);
		} else {
			// spider.addUrl(urls);
			spider.getSite().setCharset("GBK");
			spider.setExitWhenComplete(true).thread(1);
			spider.setEmptySleepTime(1000);
			spider.run();
		}
		return ret;
	}
}
